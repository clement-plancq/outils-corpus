{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outils-corpus 5\n",
    "## [Spacy](https://spacy.io)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BibliothÃ¨que logicielle de TAL Ã©crite en Python (et Cython)\n",
    "- Ã‰tiquetage POS, lemmatisation, analyse syntaxique, entitÃ©s nommÃ©es, word embedding, transformers\n",
    "- Usage de modÃ¨les neuronaux\n",
    "- IntÃ©gration aisÃ©e de bibliothÃ¨ques de deep learning\n",
    "- v3.0.3 ([github](https://github.com/explosion/spaCy))\n",
    "- Licence MIT (Open Source) pour le code\n",
    "    - Licences ouvertes diverses pour les modÃ¨les\n",
    "- Produit de la sociÃ©tÃ© [explosion.ai](https://explosion.ai/). FondÃ© par :Â Matthew Honnibal ([@honnibal](https://twitter.com/honnibal)) et Ines Montani ([@_inesmontani](https://twitter.com/_inesmontani))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pourquoi Spacy ?\n",
    "\n",
    "- C'est du Python ğŸ™Œ ğŸ‰\n",
    "- PlutÃ´t simple Ã  prendre en main\n",
    "- TrÃ¨s bien documentÃ©, Ã  notre avis. D'ailleurs plutÃ´t que ce notebook, suivez l'excellent tutorial d'Ines Montani : [https://course.spacy.io/](https://course.spacy.io/)\n",
    "- Couvre les traitements d'une chaÃ®ne de TAL typique\n",
    "- Pas mal utilisÃ© dans l'industrie\n",
    "- MAIS ce n'est pas forcÃ©ment l'outil qui donne les meilleurs rÃ©sultats pour le franÃ§ais dans toutes les tÃ¢ches de TAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy et les autres\n",
    "\n",
    "Spacy est *un* des frameworks de TAL disponibles\n",
    "\n",
    "- [NLTK](http://www.nltk.org/) :Â python, orientÃ© pÃ©dagogie, pas de modÃ¨les neuronaux inclus mais se combine bien avec TensorFlow, PyTorch ou AlleNLP\n",
    "- [Stanford CoreÂ NLP](https://stanfordnlp.github.io/stanfordnlp/) :Â java, modÃ¨les pour 53 langues (UD), rÃ©solution de la corÃ©ference.\n",
    "- [Stanza](https://stanfordnlp.github.io/stanza/) :Â python, nouveau framework de Stanford, modÃ¨les neuronaux entraÃ®nÃ©s sur donnÃ©es UD <small>[https://github.com/explosion/spacy-stanza](https://github.com/explosion/spacy-stanza) permet d'utiliser les modÃ¨les de Stanford avec Spacy</small>\n",
    "- [TextBlob](https://textblob.readthedocs.io/en/dev/)\n",
    "- [DKPro](https://dkpro.github.io/)\n",
    "- [flair](https://github.com/zalandoresearch/flair) : le framework de Zalando, trÃ¨s bonnes performances en reconnaissance d'entitÃ©s nommÃ©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## installation\n",
    "\n",
    "dans un terminal\n",
    "```bash\n",
    "python3 -m pip install -U --user spacy \n",
    "#ou pip install -U --user spacy\n",
    "```\n",
    "- installation du modÃ¨le franÃ§ais\n",
    "```bash\n",
    "python3 -m spacy download fr_core_news_md\n",
    "#ou python3 -m spacy download fr_core_news_sm \n",
    "```\n",
    "- vÃ©rification\n",
    "```bash\n",
    "python3 -m spacy validate\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## modÃ¨les\n",
    "\n",
    "- Spacy utilise des modÃ¨les statistiques qui permettent de prÃ©dire des annotations linguistiques\n",
    "- 16 langues :Â allemand, anglais, chinois, danois, espagnol, franÃ§ais, italien, japonais, lituanien, nÃ©erlandais, grec, norvÃ©gien, polonais, portugais, roumain, russe + modÃ¨le multi langues\n",
    "- 4 modÃ¨les pour le franÃ§ais\n",
    "    - fr_core_news_sm (tagger, morphologizer, lemmatizer, parser, ner) 16 Mo\n",
    "    - fr_core_news_md (tagger, morphologizer, lemmatizer, parser, ner, vectors) 45 Mo\n",
    "    - fr_core_news_lg (tagger, morphologizer, lemmatizer, parser, ner, vectors) 546 Mo\n",
    "    - fr_dep_news_trf (tagger, morphologizer, lemmatizer, parser) 381 Mo\n",
    "- modÃ¨les `fr` appris sur les corpus [Sequoia](https://deep-sequoia.inria.fr/fr/) et [WikiNer](https://figshare.com/articles/Learning_multilingual_named_entity_recognition_from_Wikipedia/5462500) sauf le modÃ¨le `trf` qui est issu de camembert-base distribuÃ© par [Hugging Face](https://huggingface.co/camembert-base).\n",
    "- Tous ces modÃ¨les, quelque soient leur type ou leur langue, s'utilisent de la mÃªme faÃ§on, avec la mÃªme API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage\n",
    "\n",
    "- *si vous voulez utiliser Spacy prenez le temps de lire la [documentation](https://spacy.io/usage), ici ce ne sera qu'un coup d'Å“il incomplet*\n",
    "- un modÃ¨le est une instance de la classe `Language`, il est adaptÃ© Ã  une langue en particulier\n",
    "- un modÃ¨le incorpore un vocabulaire, des poids, des vecteurs de mots, une configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.fr.French"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- le traitement fonctionne avec un [*pipeline*](https://spacy.io/usage/spacy-101#pipelines) pour convertir un texte en objet `Doc` (texte annotÃ©)\n",
    "- par dÃ©faut `tokenizer` > `tagger` > `parser` > `ner` > `â€¦`\n",
    "- depuis la v3 le pipeline devient `tok2vec` > `morphologizer` > `parser` > `ner` > `attribute_ruler` > `lemmatizer`  \n",
    "  ou `transformer` > `morphologizer` > `parser` > `ner` > `attribute_ruler` > `lemmatizer`\n",
    "- l'utilisateur peut ajouter des Ã©tapes ou en retrancher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f4854fb5a10>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x7f4854f4ffb0>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f4854f1d7d0>),\n",
       " ('lemmatizer', <spacy.lang.fr.lemmatizer.FrenchLemmatizer at 0x7f4854f18fa0>)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md', disable=[\"parser\", \"ner\"])\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retour au pipeline par dÃ©faut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x7f4854f933b0>),\n",
       " ('morphologizer',\n",
       "  <spacy.pipeline.morphologizer.Morphologizer at 0x7f4860c4e710>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x7f486273d600>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x7f486273d520>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x7f4854f254b0>),\n",
       " ('lemmatizer', <spacy.lang.fr.lemmatizer.FrenchLemmatizer at 0x7f4847288a50>)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.load('fr_core_news_md')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Un objet `Doc` est une sÃ©quence d'objets `Token` (voir l'[API](https://spacy.io/api/token))\n",
    " - Le texte d'origine est dÃ©coupÃ© en phrases, tokenizÃ©, annotÃ© en POS, lemme, syntaxe (dÃ©pendance) et en entitÃ©s nommÃ©es (NER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(\"Lâ€™Organisation des Nations unies (ONU) a lancÃ© mardi un appel dâ€™urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ tokenization\n",
    "\n",
    "La tokenization de Spacy est non-destructive. Vous pouvez dÃ©couper un texte en tokens et le restituer dans sa forme originale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'\n",
      "Organisation\n",
      "des\n",
      "Nations\n",
      "unies\n",
      "(\n",
      "ONU\n",
      ")\n",
      "a\n",
      "lancÃ©\n",
      "mardi\n",
      "un\n",
      "appel\n",
      "d'\n",
      "urgence\n",
      "pour\n",
      "lever\n",
      "des\n",
      "dizaines\n",
      "de\n",
      "millions\n",
      "de\n",
      "dollars\n",
      "afin\n",
      "de\n",
      "protÃ©ger\n",
      "les\n",
      "rÃ©fugiÃ©s\n",
      "vulnÃ©rables\n",
      "face\n",
      "Ã \n",
      "la\n",
      "propagation\n",
      "du\n",
      "nouveau\n",
      "coronavirus\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"L'Organisation des Nations unies (ONU) a lancÃ© mardi un appel d'urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L'Organisation des Nations unies (ONU) a lancÃ© mardi un appel d'urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus."
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text_with_ws, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ Ã©tiquetage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les annotations portant sur les tokens sont accessibles via les attributs des objets de type `token`â€¯: [https://spacy.io/api/token#attributes](https://spacy.io/api/token#attributes)  \n",
    "  - `pos_` contient l'Ã©tiquette de partie du discours de [universal dependancies](https://universaldependencies.org/docs/u/pos/)\n",
    "  - `tag_` contient l'Ã©tiquette du corpus original, parfois plus dÃ©taillÃ©e\n",
    "  - `lemma_` pour le lemme\n",
    "  - `morph` pour l'analyse morphologique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L' DET Definite=Def|Number=Sing|PronType=Art le\n",
      "Organisation NOUN Gender=Fem|Number=Sing organisation\n",
      "des ADP Definite=Def|Number=Plur|PronType=Art de\n",
      "Nations PROPN  Nations\n",
      "unies ADJ Gender=Fem|Number=Plur uni\n",
      "( PUNCT  (\n",
      "ONU PROPN Gender=Fem|Number=Sing ONU\n",
      ") PUNCT  )\n",
      "a AUX Mood=Ind|Number=Sing|Person=3|Tense=Pres|VerbForm=Fin avoir\n",
      "lancÃ© VERB Gender=Masc|Number=Sing|Tense=Past|VerbForm=Part lancer\n",
      "mardi NOUN Gender=Masc|Number=Sing mardi\n",
      "un DET Definite=Ind|Gender=Masc|Number=Sing|PronType=Art un\n",
      "appel NOUN Gender=Masc|Number=Sing appel\n",
      "d' ADP  de\n",
      "urgence NOUN Gender=Fem|Number=Sing urgence\n",
      "pour ADP  pour\n",
      "lever VERB VerbForm=Inf lever\n",
      "des DET Definite=Ind|Number=Plur|PronType=Art un\n",
      "dizaines NOUN Gender=Fem|Number=Plur dizaine\n",
      "de ADP  de\n",
      "millions NOUN Gender=Masc|NumType=Card|Number=Plur million\n",
      "de ADP  de\n",
      "dollars NOUN Gender=Masc|Number=Plur dollar\n",
      "afin ADV  afin\n",
      "de ADP  de\n",
      "protÃ©ger VERB VerbForm=Inf protÃ©ger\n",
      "les DET Definite=Def|Number=Plur|PronType=Art le\n",
      "rÃ©fugiÃ©s NOUN Gender=Masc|Number=Plur rÃ©fugiÃ©\n",
      "vulnÃ©rables ADJ Number=Plur vulnÃ©rable\n",
      "face NOUN Gender=Fem|Number=Sing face\n",
      "Ã  ADP  Ã \n",
      "la DET Definite=Def|Gender=Fem|Number=Sing|PronType=Art le\n",
      "propagation NOUN Gender=Fem|Number=Sing propagation\n",
      "du ADP Definite=Def|Gender=Masc|Number=Sing|PronType=Art de\n",
      "nouveau ADJ Gender=Masc|Number=Sing nouveau\n",
      "coronavirus NOUN Gender=Masc|Number=Sing coronavirus\n",
      ". PUNCT  .\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.morph, token.lemma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour traiter plusieurs textes en sÃ©rie, il est recommandÃ© d'utiliser [nlp.pipe](https://spacy.io/api/language#pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "    \"Cadine avait un trÃ¨s-mauvais caractÃ¨re. Elle ne sâ€™accommodait pas du rÃ´le de servante.\",\n",
    "    \"Aussi finit-elle par sâ€™Ã©tablir pour son compte.\",\n",
    "    \"Comme elle Ã©tait alors Ã¢gÃ©e de treize ans, et quâ€™elle ne pouvait rÃªver le grand commerce, un banc de vente de lâ€™allÃ©e aux fleurs, elle vendit des bouquets de violettes dâ€™un sou, piquÃ©s dans un lit de mousse, sur un Ã©ventaire dâ€™osier pendu Ã  son cou.\",\n",
    "    \"Elle rÃ´dait toute la journÃ©e dans les Halles, autour des Halles, promenant son bout de pelouse.\",\n",
    "    \"Câ€™Ã©tait lÃ  sa joie, cette flÃ¢nerie continuelle, qui lui dÃ©gourdissait les jambes, qui la tirait des longues heures passÃ©es Ã  faire des bouquets, les genoux pliÃ©s, sur une chaise basse.\",\n",
    "    \"Maintenant, elle tournait ses violettes en marchant, elle les tournait comme des fuseaux, avec une merveilleuse lÃ©gÃ¨retÃ© de doigts ; elle comptait six Ã  huit fleurs, selon la saison, pliait en deux un brin de jonc, ajoutait une feuille, roulait un fil mouillÃ© ; et, entre ses dents de jeune loup, elle cassait le fil.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = nlp.pipe(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€Â vous  \n",
    "1. Extrayez de la sÃ©rie de phrases ci-dessus la liste des noms communs\n",
    "2. Comptez le nombre de tokens au masculin et au fÃ©minin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chaise, commerce, fil, banc, bouquets, violettes, fil, fuseaux, mousse, rÃ´le, compte, bout, heures, osier, saison, brin, ans, feuille, vente, allÃ©e, violettes, -, sou, lÃ©gÃ¨retÃ©, servante, Halles, pelouse, jambes, bouquets, fleurs, genoux, dents, fleurs, loup, Cadine, caractÃ¨re, joie, journÃ©e, flÃ¢nerie, lit, Ã©ventaire, Halles, doigts, cou\n"
     ]
    }
   ],
   "source": [
    "# Extrayez de la sÃ©rie de phrases ci-dessus la liste des noms communs\n",
    "\n",
    "ncs = []\n",
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    for token in doc:\n",
    "        if token.pos_ == \"NOUN\":\n",
    "            ncs.append(token)\n",
    "\n",
    "ncs_set = set(ncs)\n",
    "#for item in ncs:\n",
    "#    print(item.text)\n",
    "print(\", \".join([item.text for item in ncs_set]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens au masculin : 39, tokens au fÃ©minin : 47\n"
     ]
    }
   ],
   "source": [
    "# Comptez le nombre de tokens au masculin et au fÃ©minin\n",
    "\n",
    "nb_masc = 0\n",
    "nb_fem = 0\n",
    "\n",
    "docs = nlp.pipe(texts)\n",
    "for doc in docs:\n",
    "    for token in doc:\n",
    "        if token.morph.get(\"Gender\") == [\"Masc\"]:\n",
    "            nb_masc += 1\n",
    "        elif token.morph.get(\"Gender\") == [\"Fem\"]:\n",
    "            nb_fem += 1\n",
    "            \n",
    "print(f\"tokens au masculin : {nb_masc}, tokens au fÃ©minin : {nb_fem}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si NER (*Named Entity Recognition*) fait partie de votre modÃ¨le, vos donnÃ©es seront annotÃ©es Ã©galement en entitÃ©s nommÃ©es.  \n",
    "Vous pouvez y accÃ©der avec l'attribut `ent_type_` des tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L' \n",
      "Organisation ORG\n",
      "des ORG\n",
      "Nations ORG\n",
      "unies ORG\n",
      "( \n",
      "ONU ORG\n",
      ") \n",
      "a \n",
      "lancÃ© \n",
      "mardi \n",
      "un \n",
      "appel \n",
      "dâ€™ \n",
      "urgence \n",
      "pour \n",
      "lever \n",
      "des \n",
      "dizaines \n",
      "de \n",
      "millions \n",
      "de \n",
      "dollars \n",
      "afin \n",
      "de \n",
      "protÃ©ger \n",
      "les \n",
      "rÃ©fugiÃ©s \n",
      "vulnÃ©rables \n",
      "face \n",
      "Ã  \n",
      "la \n",
      "propagation \n",
      "du \n",
      "nouveau \n",
      "coronavirus \n",
      ". \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"L'Organisation des Nations unies (ONU) a lancÃ© mardi un appel dâ€™urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "for token in doc:\n",
    "    print(token, token.ent_type_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou accÃ©der directement aux entitÃ©s de l'objet `Doc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Organisation des Nations unies ORG\n",
      "ONU ORG\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"fr_core_news_md\")\n",
    "doc = nlp(\"Lâ€™Organisation des Nations unies (ONU) a lancÃ© mardi un appel dâ€™urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.\")\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy intÃ¨gre un outil de visualisation pour l'annotation en entitÃ©s nommÃ©es :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">L'\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Organisation des Nations unies\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " (\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ONU\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ") a lancÃ© mardi un appel dâ€™urgence pour lever des dizaines de millions de dollars afin de protÃ©ger les rÃ©fugiÃ©s vulnÃ©rables face Ã  la propagation du nouveau coronavirus.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Le prÃ©sident \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Xi Jinping\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " a affirmÃ© que la propagation du coronavirus Ã©tait Â«â€¯pratiquement jugulÃ©eâ€¯Â». Il sâ€™est dâ€™ailleurs rendu pour la premiÃ¨re fois Ã  \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Wuhan\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", la capitale de la province du \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Hubei\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", le berceau du \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Covid-19\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MISC</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp('Le prÃ©sident Xi Jinping a affirmÃ© que la propagation du coronavirus Ã©tait Â«â€¯pratiquement jugulÃ©eâ€¯Â». Il sâ€™est dâ€™ailleurs rendu pour la premiÃ¨re fois Ã  Wuhan, la capitale de la province du Hubei, le berceau du Covid-19.')\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">DerriÃ¨re lui, sur le carreau de la \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    rue Rambuteau\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", on vendait des fruits.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.\")\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€Â vous  \n",
    "\n",
    "Dans `files/Le_Ventre_de_Paris-short.txt` (ou un texte de votre choix), comptez la frÃ©quence de chaque entitÃ© de type PER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Florent', 218), ('Lisa', 76), ('Claude', 33), ('Pauline', 22), ('Saget', 18), ('LecÅ“ur', 18), ('Auguste', 18), ('Augustine', 16), ('FranÃ§ois', 15), ('Charvet', 15), ('Lebigre', 13), ('LÃ©on', 13), ('Robine', 11), ('MÃ©hudin', 10), ('madame Quenu', 9), ('Gradelle', 8), ('ClÃ©mence', 8), ('Balthazar', 6), ('Alexandre', 6), ('Madame FranÃ§ois', 5), ('Chantemesse', 5), ('Jules', 5), ('Marjolin', 5), ('Claude Lantier', 5), ('Quenu', 5), ('Collard', 5), ('Louise', 5), ('Claire', 5), ('Murillo', 4), ('Macquart', 4), ('Mademoiselle Saget', 4), ('Verlaque', 4), ('Hein', 3), ('Voyons', 3), ('Cadine', 3), ('Madame LecÅ“ur', 3), ('Gavard', 3), ('Rose', 3), ('Augustine Landois', 2), ('Charles X', 2), ('Louis-Philippe', 2), ('Madame Taboureau', 2), ('Mouton', 2), ('Doucement', 2), ('Ã‰chappÃ© de Cayenne', 1), ('Marcel', 1), ('Dis Marcel', 1), ('Lacaille', 1), ('Lundi', 1), ('Adieu', 1), ('Cendrillon', 1), ('Rubens', 1), ('Guillout', 1), ('AveuglÃ©', 1), ('de Florent', 1), ('Cuvier', 1), ('Gavard voulut', 1), ('Gutenberg', 1), ('Pardieu', 1), ('Florent LaquerriÃ¨re', 1), ('Auguste Landois', 1), ('Saint-Ouen', 1), ('NapolÃ©on III', 1), ('Morny', 1), ('Monsieur', 1), ('MÃ©nilmontant', 1), ('Ã‰coute', 1), ('Jean-Jacques Rousseau', 1), ('Louise MÃ©hudin', 1), ('Allez', 1), ('madame Taboureau', 1), ('Quarante', 1), ('Madame Robine', 1), ('Monsieur Manoury', 1), ('Gavard prÃ©senta Florent', 1), ('Manoury', 1), ('Logre', 1), ('la Vierge', 1)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "personnes = Counter()\n",
    "with open('files/Le_Ventre_de_Paris-short.txt') as input_data:\n",
    "    docs = nlp.pipe(input_data)\n",
    "    for doc in docs:\n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PER\":\n",
    "                personnes[ent.text] += 1\n",
    "\n",
    "print(personnes.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## usage â€“ analyse syntaxique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse syntaxique ou *parsing* de Spacy est une analyse en dÃ©pendance. La plupart sinon la totalitÃ© des modÃ¨les utilisÃ©s viennent de https://universaldependencies.org\n",
    "\n",
    "Dans l'analyse en dÃ©pendance produite par Spacy, chaque mot d'une phrase a un gouverneur unique (*head*), la relation de dÃ©pendance entre le mot et son gouverneur est typÃ©e (*nsubj*, *obj*, â€¦).  \n",
    "Pour la tÃªte de la phrase on utilise la relation *ROOT*.\n",
    "\n",
    "La structure produite par l'analyse syntaxique est un arbre, un graphe acyclique et connexe. Les tokens sont les nÅ“uds, les arcs sont les dÃ©pendances, le type de la relation est l'Ã©tiquette de l'arc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`displacy` fournit un outil de visualisation bien pratique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"fr\" id=\"4abe6432a18348afa1a8c82b2ebe2189-0\" class=\"displacy\" width=\"1220\" height=\"362.0\" direction=\"ltr\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">DerriÃ¨re</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">lui,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">sur</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">le</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">carreau</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">la</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">rue</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">Rambuteau,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">on</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">vendait</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">des</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">fruits.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-0\" stroke-width=\"2px\" d=\"M70,227.0 C70,182.0 120.0,182.0 120.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,229.0 L62,217.0 78,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-1\" stroke-width=\"2px\" d=\"M160,227.0 C160,2.0 950.0,2.0 950.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M160,229.0 L152,217.0 168,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-2\" stroke-width=\"2px\" d=\"M250,227.0 C250,137.0 395.0,137.0 395.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M250,229.0 L242,217.0 258,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-3\" stroke-width=\"2px\" d=\"M340,227.0 C340,182.0 390.0,182.0 390.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M340,229.0 L332,217.0 348,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-4\" stroke-width=\"2px\" d=\"M430,227.0 C430,47.0 945.0,47.0 945.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obl:mod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,229.0 L422,217.0 438,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-5\" stroke-width=\"2px\" d=\"M520,227.0 C520,137.0 665.0,137.0 665.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M520,229.0 L512,217.0 528,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-6\" stroke-width=\"2px\" d=\"M610,227.0 C610,182.0 660.0,182.0 660.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M610,229.0 L602,217.0 618,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-7\" stroke-width=\"2px\" d=\"M430,227.0 C430,92.0 670.0,92.0 670.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M670.0,229.0 L678.0,217.0 662.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-8\" stroke-width=\"2px\" d=\"M700,227.0 C700,182.0 750.0,182.0 750.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M750.0,229.0 L758.0,217.0 742.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-9\" stroke-width=\"2px\" d=\"M880,227.0 C880,182.0 930.0,182.0 930.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880,229.0 L872,217.0 888,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-10\" stroke-width=\"2px\" d=\"M1060,227.0 C1060,182.0 1110.0,182.0 1110.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1060,229.0 L1052,217.0 1068,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-4abe6432a18348afa1a8c82b2ebe2189-0-11\" stroke-width=\"2px\" d=\"M970,227.0 C970,137.0 1115.0,137.0 1115.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-4abe6432a18348afa1a8c82b2ebe2189-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1115.0,229.0 L1123.0,217.0 1107.0,217.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.\")\n",
    "displacy.render(doc, style=\"dep\", jupyter=True, options={'distance':90})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il existe Ã©galement un outil issu d'un dÃ©veloppement indÃ©pendant :Â [explacy](https://spacy.io/universe/project/explacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep tree     Token     Dep type Lemma     Part of Sp\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "         â”Œâ”€â–º DerriÃ¨re  case     derriÃ¨re  ADP       \n",
      "â”Œâ”€â”€â”€â”€â”€â”€â”€â–ºâ””â”€â”€ lui       obl:mod  lui       PRON      \n",
      "â”‚â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ,         punct    ,         PUNCT     \n",
      "â”‚â”‚      â”Œâ”€â”€â–º sur       case     sur       ADP       \n",
      "â”‚â”‚      â”‚â”Œâ”€â–º le        det      le        DET       \n",
      "â”‚â”‚â”Œâ”€â–ºâ”Œâ”€â”€â”´â”´â”€â”€ carreau   obl:mod  carreau   NOUN      \n",
      "â”‚â”‚â”‚  â”‚  â”Œâ”€â”€â–º de        case     de        ADP       \n",
      "â”‚â”‚â”‚  â”‚  â”‚â”Œâ”€â–º la        det      le        DET       \n",
      "â”‚â”‚â”‚  â””â”€â–ºâ””â”¼â”€â”€ rue       nmod     rue       NOUN      \n",
      "â”‚â”‚â”‚      â””â”€â–º Rambuteau nmod     Rambuteau PROPN     \n",
      "â”‚â”‚â”‚     â”Œâ”€â”€â–º ,         punct    ,         PUNCT     \n",
      "â”‚â”‚â”‚     â”‚â”Œâ”€â–º on        nsubj    on        PRON      \n",
      "â””â”´â”´â”€â”€â”¬â”¬â”€â”´â”´â”€â”€ vendait   ROOT     vendre    VERB      \n",
      "     â”‚â”‚  â”Œâ”€â–º des       det      un        DET       \n",
      "     â”‚â””â”€â–ºâ””â”€â”€ fruits    obj      fruit     NOUN      \n",
      "     â””â”€â”€â”€â”€â”€â–º .         punct    .         PUNCT     \n"
     ]
    }
   ],
   "source": [
    "import explacy\n",
    "explacy.print_parse_info(nlp, 'DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut aussi rÃ©cupÃ©rer parcourir les tokens et afficher "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maintenant ADVMOD tournait\n",
      ", PUNCT tournait\n",
      "elle NSUBJ tournait\n",
      "tournait ROOT tournait\n",
      "ses DET violettes\n",
      "violettes OBJ tournait\n",
      "en CASE marchant\n",
      "marchant ADVCL tournait\n",
      ", PUNCT tournait\n",
      "elle NSUBJ tournait\n",
      "les OBJ tournait\n",
      "tournait CONJ tournait\n",
      "comme CASE fuseaux\n",
      "des DET fuseaux\n",
      "fuseaux OBL:MOD tournait\n",
      ", PUNCT tournait\n",
      "avec CASE lÃ©gÃ¨retÃ©\n",
      "une DET lÃ©gÃ¨retÃ©\n",
      "merveilleuse AMOD lÃ©gÃ¨retÃ©\n",
      "lÃ©gÃ¨retÃ© OBL:MOD tournait\n",
      "de CASE doigts\n",
      "doigts NMOD lÃ©gÃ¨retÃ©\n",
      "; PUNCT tournait\n",
      "elle NSUBJ comptait\n",
      "comptait ROOT comptait\n",
      "six NUMMOD fleurs\n",
      "Ã  CASE huit\n",
      "huit NMOD six\n",
      "fleurs OBJ comptait\n",
      ", PUNCT comptait\n",
      "selon CASE saison\n",
      "la DET saison\n",
      "saison OBL:MOD comptait\n",
      ", PUNCT pliait\n",
      "pliait CONJ comptait\n",
      "en CASE deux\n",
      "deux OBL:MOD pliait\n",
      "un DET brin\n",
      "brin OBJ pliait\n",
      "de CASE jonc\n",
      "jonc NMOD brin\n",
      ", PUNCT ajoutait\n",
      "ajoutait CONJ comptait\n",
      "une DET feuille\n",
      "feuille OBJ ajoutait\n",
      ", PUNCT roulait\n",
      "roulait CONJ comptait\n",
      "un DET fil\n",
      "fil OBJ roulait\n",
      "mouillÃ© AMOD fil\n",
      "; PUNCT comptait\n",
      "et CC cassait\n",
      ", PUNCT cassait\n",
      "entre CASE dents\n",
      "ses DET dents\n",
      "dents OBL:MOD cassait\n",
      "de CASE loup\n",
      "jeune AMOD loup\n",
      "loup NMOD dents\n",
      ", PUNCT cassait\n",
      "elle NSUBJ cassait\n",
      "cassait ROOT cassait\n",
      "le DET fil\n",
      "fil OBJ cassait\n",
      ". PUNCT cassait\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.dep_.upper(), token.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les attributs de token suivant peuvent Ãªtre utilisÃ©s pour parcourir l'arbre de dÃ©pendance :Â \n",
    "- `children` les tokens dÃ©pendants du token\n",
    "- `subtree` tous les descendants du token\n",
    "- `ancestors` tous les parents du token\n",
    "- `rights` les enfants Ã  droite du token\n",
    "- `lefts` les enfants Ã  gauche du token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut extraire de la phrase prÃ©cÃ©dente le triplet sujet-verbe-objet comme ceci :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(on, vendait, fruits)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = [token for token in doc if token.head == token][0]\n",
    "subjects = [tok for tok in root.lefts if tok.dep_ == \"nsubj\"]\n",
    "subject = subjects[0]\n",
    "objs = [tok for tok in root.rights if tok.dep_ == \"obj\"]\n",
    "obj = objs[0]\n",
    "subject, root, obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "des\n",
      "fruits\n"
     ]
    }
   ],
   "source": [
    "for obj in objs:\n",
    "    for descendant in obj.subtree:\n",
    "        print(descendant.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€Â vous\n",
    "\n",
    "1. Trouver et afficher l'objet de la phrase :Â Â« Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle. Â»\n",
    "\n",
    "2. Dans la liste `texts` vue plus haut, retrouvez les verbes dont Cadine ou le pronom 'elle' est sujet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dep tree                         Token      Dep type   Lemma      Part of Sp\n",
      "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
      "                          â”Œâ”€â”€â”€â”€â–º Depuis     mark       depuis     ADP       \n",
      "                          â”‚â”Œâ”€â”€â”€â–º que        mark       que        SCONJ     \n",
      "                          â”‚â”‚â”Œâ”€â”€â–º Google     nsubj      Google     PROPN     \n",
      "                          â”‚â”‚â”‚â”Œâ”€â–º a          aux:tense  avoir      AUX       \n",
      "â”Œâ”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”´â”´â”´â”€â”€ annoncÃ©    advcl      annoncer   VERB      \n",
      "â”‚  â”‚                         â”Œâ”€â–º son        det        son        DET       \n",
      "â”‚  â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ intention  obj        intention  NOUN      \n",
      "â”‚     â”‚                      â”Œâ”€â–º de         mark       de         ADP       \n",
      "â”‚     â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ stopper    acl        stopper    VERB      \n",
      "â”‚        â”‚                â”Œâ”€â–ºâ”Œâ”€â”€ d'         advmod     de         ADP       \n",
      "â”‚        â”‚                â”‚  â””â”€â–º ici        fixed      ici        ADV       \n",
      "â”‚        â”‚                â”‚  â”Œâ”€â–º deux       nummod     deux       NUM       \n",
      "â”‚        â”‚             â”Œâ”€â–ºâ””â”€â”€â”´â”€â”€ ans        nmod       an         NOUN      \n",
      "â”‚        â”‚             â”‚     â”Œâ”€â–º les        det        le         DET       \n",
      "â”‚        â””â”€â–ºâ”Œâ”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”¬â”€â”€â”¼â”€â”€ cookies    obj        cookie     NOUN      \n",
      "â”‚           â”‚â”‚            â”‚  â””â”€â–º tiers      amod       tiers      ADJ       \n",
      "â”‚           â”‚â”‚            â”‚  â”Œâ”€â–º sur        case       sur        ADP       \n",
      "â”‚           â”‚â”‚            â””â”€â–ºâ””â”€â”€ Chrome     nmod       Chrome     PROPN     \n",
      "â”‚           â”‚â”‚              â”Œâ”€â”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚           â”‚â”‚              â”‚â”Œâ”€â–º son        det        son        DET       \n",
      "â”‚           â”‚â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”´â”´â”€â”€ moteur     conj       moteur     NOUN      \n",
      "â”‚           â”‚   â”‚         â”‚  â”Œâ”€â–º de         case       de         ADP       \n",
      "â”‚           â”‚   â”‚         â””â”€â–ºâ””â”€â”€ recherche  nmod       recherche  NOUN      \n",
      "â”‚           â”‚   â”‚           â”Œâ”€â”€â–º qui        nsubj:pass qui        PRON      \n",
      "â”‚           â”‚   â”‚           â”‚â”Œâ”€â–º est        aux:pass   Ãªtre       AUX       \n",
      "â”‚           â”‚   â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”´â”€â”€ utilisÃ©    acl:relcl  utiliser   VERB      \n",
      "â”‚           â”‚      â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–º par        case       par        ADP       \n",
      "â”‚           â”‚      â”‚  â”‚   â”Œâ”€â–ºâ”Œâ”€â”€ plus       advmod     plus       ADV       \n",
      "â”‚           â”‚      â”‚  â”‚   â”‚  â””â”€â–º de         fixed      de         ADP       \n",
      "â”‚           â”‚      â”‚  â”‚â”Œâ”€â–ºâ””â”€â”€â”€â”€â”€ 60         nummod     60         NUM       \n",
      "â”‚           â”‚      â””â”€â–ºâ””â”´â”€â”¬â”€â”€â”€â”€â”€â”€ %          obl:agent  pourcent   NOUN      \n",
      "â”‚           â”‚            â”‚  â”Œâ”€â”€â–º de         case       de         ADP       \n",
      "â”‚           â”‚            â”‚  â”‚â”Œâ”€â–º la         det        le         DET       \n",
      "â”‚           â”‚            â””â”€â–ºâ”œâ”¼â”€â”€ population nmod       population NOUN      \n",
      "â”‚           â”‚               â”‚â””â”€â–º mondiale   amod       mondial    ADJ       \n",
      "â”‚           â”‚               â””â”€â”€â–º connectÃ©e  acl        connecter  VERB      \n",
      "â”‚           â”‚               â”Œâ”€â”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚           â”‚               â”‚â”Œâ”€â–º les        det        le         DET       \n",
      "â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”Œâ”¬â”€â”´â”´â”€â”€ Criteo     conj       Criteo     PROPN     \n",
      "â”‚                        â”‚â”‚  â”Œâ”€â–º ,          punct      ,          PUNCT     \n",
      "â”‚                        â”‚â””â”€â–ºâ””â”€â”€ LiveRamp   conj       LiveRamp   PROPN     \n",
      "â”‚                        â”‚  â”Œâ”€â”€â–º et         cc         et         CCONJ     \n",
      "â”‚                        â”‚  â”‚â”Œâ”€â–º autres     amod       autre      ADJ       \n",
      "â”‚                        â””â”€â–ºâ””â”¼â”€â”€ Index      conj       index      NOUN      \n",
      "â”‚                            â””â”€â–º Exchange   nmod       Exchange   PROPN     \n",
      "â”‚                            â”Œâ”€â–º se         expl:comp  se         PRON      \n",
      "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ prÃ©parent  ROOT       prÃ©parer   VERB      \n",
      "             â”‚â”‚              â”Œâ”€â–º Ã           case       Ã           ADP       \n",
      "             â”‚â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ ce         obl:arg    ce         PRON      \n",
      "             â”‚   â”‚           â”Œâ”€â–º qui        nsubj      qui        PRON      \n",
      "             â”‚   â””â”€â–ºâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€ peut       acl:relcl  pouvoir    VERB      \n",
      "             â”‚      â”‚        â”Œâ”€â–º Ãªtre       aux:pass   Ãªtre       AUX       \n",
      "             â”‚      â””â”€â–ºâ”Œâ”¬â”¬â”€â”€â”€â”´â”€â”€ considÃ©rÃ©  xcomp      considÃ©rer VERB      \n",
      "             â”‚         â”‚â”‚â”‚  â”Œâ”€â”€â–º comme      case       comme      ADP       \n",
      "             â”‚         â”‚â”‚â”‚  â”‚â”Œâ”€â–º un         det        un         DET       \n",
      "             â”‚         â”‚â”‚â””â”€â–ºâ””â”´â”€â”€ sÃ©isme     obl:mod    sÃ©isme     NOUN      \n",
      "             â”‚         â”‚â””â”€â”€â”€â”€â”€â”€â–º ,          punct      ,          PUNCT     \n",
      "             â”‚         â”‚    â”Œâ”€â”€â–º Ã           case       Ã           ADP       \n",
      "             â”‚         â”‚    â”‚â”Œâ”€â–º leur       det        leur       DET       \n",
      "             â”‚         â””â”€â”€â”€â–ºâ””â”´â”€â”€ Ã©chelle    obl:mod    Ã©chelle    NOUN      \n",
      "             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º .          punct      .          PUNCT     \n"
     ]
    }
   ],
   "source": [
    "import explacy\n",
    "explacy.print_parse_info(nlp, \"Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Depuis que Google a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "root = [token for token in doc if token.head == token][0]\n",
    "objs = [tok for tok in root.rights if tok.dep_ in (\"obl:arg\", \"obj\", \"iobj\")]\n",
    "for obj in objs:\n",
    "    for descendant in obj.subtree:\n",
    "        print(descendant.text_with_ws, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Matching par rÃ¨gle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spacy a une classe `Matcher` qui permet de repÃ©rer des tokens ou des suites de tokens Ã  l'aide de patrons (*pattern*). Ces patrons peuvent porter sur la forme des tokens ou leurs attributs (pos, ent).  \n",
    "On peut aussi utiliser des catÃ©gories comme `IS_ALPHA` ou `IS_NUM`, voir la [doc](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 8 en taille XL\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "# en taille + lettres en maj\n",
    "matcher.add(\"tailles\", [pattern])\n",
    "\n",
    "doc = nlp(\"Ce modÃ¨le est aussi disponible en taille XL ; je vous le conseille.\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ã‡a fonctionne pour les sÃ©quences comme Â« en taille M Â» ou Â« en taille XL Â» mais pas pour Â« vous l'avez en XL ? Â»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut essayer d'amÃ©liorer les rÃ¨gles :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en XL\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"IS_ALPHA\": True, \"IS_UPPER\": True}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# rÃ¨gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ou encore :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9364735015326875510 tailles 3 5 en XL\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "sizes = ['XS', 'S', 'M', 'L', 'XL']\n",
    "pattern_1 = [{\"LOWER\": \"en\"}, {\"LOWER\": \"taille\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "pattern_2 = [{\"LOWER\": \"en\"}, {\"TEXT\": {\"IN\": sizes}}]\n",
    "matcher.add(\"tailles\", [pattern_1, pattern_2])\n",
    "# rÃ¨gle avec deux patterns\n",
    "\n",
    "doc = nlp(\"vous l'avez en XL ?\")\n",
    "matches = matcher(doc)\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(match_id, string_id, start, end, span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€ vous\n",
    "\n",
    "Dans `files/Le_Ventre_de_Paris-short.txt`, trouver les sÃ©quences pronom - le lemme 'vendre'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\": \"PRON\"}, {\"LEMMA\": \"vendre\"}]\n",
    "matcher.add(\"pro_vendre\", [pattern])\n",
    "\n",
    "doc = \"\"\n",
    "with open('files/Le_Ventre_de_Paris-short.txt') as input_data:\n",
    "    doc = nlp(input_data.read())\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elle vend\n",
      "on vendait\n",
      "qui vendait\n",
      "qui vendaient\n",
      "elle vendait\n",
      "Il vendrait\n"
     ]
    }
   ],
   "source": [
    "for _, start, end in matches:\n",
    "    #string_id = nlp.vocab.strings[match_id]  # Get string representation\n",
    "    span = doc[start:end]  # The matched span\n",
    "    print(span.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dependency Matcher :Â extraction de patrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis la v3, Spacy a ajoutÃ© un *Dependancy Matcher* qui permet de faire de l'extraction de patrons syntaxiques. Il est maintenant possible de faire porter des requÃªtes sur l'arbre syntaxique et non plus seulement sur la sÃ©quence des tokens.  \n",
    "Ce dispositif utilise [Semgrex](https://nlp.stanford.edu/nlp/javadoc/javanlp/edu/stanford/nlp/semgraph/semgrex/SemgrexPattern.html), la syntaxe utilisÃ©e dans Tgrep et Tregex, les outils de requÃªte sur Treebank de Stanford.\n",
    "\n",
    "Voir la [documentation](https://spacy.io/usage/rule-based-matching#dependencymatcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventre_short = \"\"\n",
    "with open('files/Le_Ventre_de_Paris-short.txt') as input_f:\n",
    "    ventre_short = input_f.read()\n",
    "doc = nlp(ventre_short)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vend\n",
      "vendant\n",
      "vendait\n",
      "vendait\n",
      "vendaient\n",
      "vendaient\n",
      "vend\n",
      "vendu\n",
      "vendu\n",
      "vendre\n",
      "vendait\n",
      "vendu\n",
      "vendais\n",
      "vendu\n",
      "vendrait\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "  {\n",
    "    \"RIGHT_ID\": \"vendre\",    \n",
    "    \"RIGHT_ATTRS\": {\"LEMMA\": \"vendre\"}\n",
    "  }\n",
    "]\n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for m_id, t_ids in matches:\n",
    "    for t_id in t_ids:\n",
    "        print(doc[t_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verbe, sujet, objet :Â  acheta -> il -> derniers\n",
      "objet complet :Â  ses deux derniers sous de pain\n",
      "Phrase complÃ©te :Â  Mais, Ã  Vernon, il acheta ses deux derniers sous de pain.\n",
      "\n",
      "verbe, sujet, objet :Â  achetait -> elle -> quâ€™\n",
      "objet complet :Â  quâ€™\n",
      "Phrase complÃ©te :Â  Jâ€™Ã©tais gamine, quâ€™elle achetait dÃ©jÃ  ses navets Ã  mon pÃ¨re.\n",
      "\n",
      "verbe, sujet, objet :Â  achetait -> elle -> navets\n",
      "objet complet :Â  ses navets Ã  mon pÃ¨re\n",
      "Phrase complÃ©te :Â  Jâ€™Ã©tais gamine, quâ€™elle achetait dÃ©jÃ  ses navets Ã  mon pÃ¨re.\n",
      "\n",
      "verbe, sujet, objet :Â  vendait -> on -> fruits\n",
      "objet complet :Â  des fruits\n",
      "Phrase complÃ©te :Â  \n",
      "\n",
      "DerriÃ¨re lui, sur le carreau de la rue Rambuteau, on vendait des fruits.\n",
      "\n",
      "verbe, sujet, objet :Â  vendaient -> qui -> bottes\n",
      "objet complet :Â  des bottes de fougÃ¨re et des paquets de feuilles de vigne , bien rÃ©guliers , attachÃ©s par quarterons\n",
      "Phrase complÃ©te :Â  Ils sâ€™arrÃªtÃ¨rent curieusement devant des femmes qui vendaient des bottes de fougÃ¨re et des paquets de feuilles de vigne, bien rÃ©guliers, attachÃ©s par quarterons.\n",
      "\n",
      "verbe, sujet, objet :Â  vend -> Lui -> volaille\n",
      "objet complet :Â  toute la volaille quâ€™ il veut\n",
      "Phrase complÃ©te :Â  Lui, vend toute la volaille quâ€™il veutâ€¦\n",
      "\n",
      "verbe, sujet, objet :Â  achetait -> il -> morceau\n",
      "objet complet :Â  un morceau de dinde ou un morceau dâ€™ oie de douze\n",
      "Phrase complÃ©te :Â  Quand Florent rentrait trop tard pour faire cuire quelque bout de viande, il achetait en bas un morceau de dinde ou un morceau dâ€™oie de douze sous.\n",
      "\n",
      "verbe, sujet, objet :Â  vendu -> Il -> mobilier\n",
      "objet complet :Â  le pauvre mobilier de la rue Royer\n",
      "Phrase complÃ©te :Â  Il avait vendu le pauvre mobilier de la rue Royer-Collard, et en gardait lâ€™argent, quarante et quelques francs, pour que ce farceur de Quenu, disait-il, ne le jetÃ¢t pas par les fenÃªtres.\n",
      "\n",
      "verbe, sujet, objet :Â  vendait -> elle -> oÃ¹\n",
      "objet complet :Â  oÃ¹\n",
      "Phrase complÃ©te :Â  Lorsquâ€™elle le vit sâ€™Ã©tablir aux Halles, Ã  deux pas du pavillon oÃ¹ elle vendait du beurre, des fromages et des Å“ufs, elle lâ€™accusa dâ€™avoir Â« inventÃ© Ã§a pour la taquiner et lui porter mauvaise chance.\n",
      "\n",
      "verbe, sujet, objet :Â  vendait -> elle -> beurre\n",
      "objet complet :Â  du beurre , des fromages et des Å“ufs\n",
      "Phrase complÃ©te :Â  Lorsquâ€™elle le vit sâ€™Ã©tablir aux Halles, Ã  deux pas du pavillon oÃ¹ elle vendait du beurre, des fromages et des Å“ufs, elle lâ€™accusa dâ€™avoir Â« inventÃ© Ã§a pour la taquiner et lui porter mauvaise chance.\n",
      "\n",
      "verbe, sujet, objet :Â  achetÃ© -> Je -> vous\n",
      "objet complet :Â  vous\n",
      "Phrase complÃ©te :Â  Je vous en ai achetÃ© avant-hier, du boudinâ€¦\n",
      "\n",
      "verbe, sujet, objet :Â  vendu -> vous -> mâ€™\n",
      "objet complet :Â  mâ€™\n",
      "Phrase complÃ©te :Â  Elle se courba, les poings sur son comptoir ; et, dâ€™une voix un peu rauque :\n",
      "\n",
      "â€” Dites donc, la semaine derniÃ¨re, quand vous mâ€™avez vendu cette paire de soles, vous savez, est-ce que je suis allÃ©e vous dire quâ€™elles Ã©taient pourries devant le monde !\n",
      "\n",
      "verbe, sujet, objet :Â  vendu -> vous -> paire\n",
      "objet complet :Â  cette paire de soles\n",
      "Phrase complÃ©te :Â  Elle se courba, les poings sur son comptoir ; et, dâ€™une voix un peu rauque :\n",
      "\n",
      "â€” Dites donc, la semaine derniÃ¨re, quand vous mâ€™avez vendu cette paire de soles, vous savez, est-ce que je suis allÃ©e vous dire quâ€™elles Ã©taient pourries devant le monde !\n",
      "\n",
      "verbe, sujet, objet :Â  vendrait -> Il -> semelles\n",
      "objet complet :Â  des semelles de bottes\n",
      "Phrase complÃ©te :Â  Il vendrait des semelles de bottes pour des paires de soles.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"vendre\",    \n",
    "        \"RIGHT_ATTRS\": {\"LEMMA\": {\"IN\": [\"vendre\", \"acheter\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"sujet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\"},  \n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"vendre\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"objet\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": {\"IN\": [\"obj\", \"iobj\", \"obl\"]}},  \n",
    "    }\n",
    "]\n",
    "matcher.add(\"VENDRE\", [pattern])\n",
    "matches = matcher(doc)\n",
    "for m_id, t_ids in matches:\n",
    "    print(\"verbe, sujet, objet :Â \", \" -> \".join([doc[t_id].text for t_id in t_ids]))\n",
    "    print(\"objet complet :Â \", \" \".join([t.text for t in doc[t_ids[2]].subtree]))\n",
    "    print(\"Phrase complÃ©te :Â \", doc[t_ids[0]].sent)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âœï¸ Ã€ vous\n",
    "\n",
    "Ajouter une rÃ¨gle au motif pour trouver aussi l'objet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapter les traitements de Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. re-tokenisation\n",
    "\n",
    "- voir [https://spacy.io/usage/linguistic-features#retokenization](https://spacy.io/usage/linguistic-features#retokenization)\n",
    "\n",
    "Dans l'exemple qui suit Â« quer-cra Â» sera tokenizÃ© Ã  tort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pour', 'ADP', 'pour'), ('les', 'DET', 'le'), ('bons', 'ADJ', 'bon'), ('bails', 'NOUN', 'bail'), ('Ã§a', 'PRON', 'cela'), ('va', 'VERB', 'aller'), ('grave', 'ADJ', 'grave'), ('quer', 'VERB', 'quer'), ('-', 'PUNCT', '-'), ('cra', 'PROPN', 'cra')]\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Pour les bons bails Ã§a va grave quer-cra\")\n",
    "print([(tok.text, tok.pos_, tok.lemma_)for tok in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pour', 'ADP'), ('les', 'DET'), ('bons', 'ADJ'), ('bails', 'NOUN'), ('Ã§a', 'PRON'), ('va', 'VERB'), ('grave', 'ADJ'), ('quer-cra', 'NOUN')]\n"
     ]
    }
   ],
   "source": [
    "with doc.retokenize() as retokenizer:\n",
    "    retokenizer.merge(doc[7:], attrs={\"LEMMA\": \"quer-cra\", \"POS\": \"NOUN\"})\n",
    "print([(tok.text, tok.pos_) for tok in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention ici câ€™est lâ€™objet doc qui est modifiÃ©, le rÃ©sultat mais pas le traitement. Nous allons voir comment faire pour modifier le traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Modification de la tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pour', 'ADP', 'pour'), ('les', 'DET', 'le'), ('bons', 'ADJ', 'bon'), ('bails', 'NOUN', 'bail'), ('Ã§a', 'PRON', 'cela'), ('va', 'VERB', 'aller'), ('grave', 'ADJ', 'grave'), ('quer-cra', 'PROPN', 'quer-cra')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH, LEMMA, POS, TAG\n",
    "\n",
    "special_case = [{ORTH: \"quer-cra\"}]\n",
    "nlp.tokenizer.add_special_case(\"quer-cra\", special_case)\n",
    "doc = nlp(\"Pour les bons bails Ã§a va grave quer-cra\")\n",
    "print([(tok.text, tok.pos_, tok.lemma_) for tok in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a bien modifiÃ© la tokenisation dans le modÃ¨le `nlp`. Cela n'affecte pas par contre l'Ã©tiquetage en POS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. EntitÃ©s nommÃ©es :Â traitement par rÃ¨gles\n",
    " - Voir [https://spacy.io/usage/rule-based-matching#entityruler](https://spacy.io/usage/rule-based-matching#entityruler)\n",
    " \n",
    "Spacy offre aussi un mÃ©canisme de traitement par rÃ¨gle pour les entitÃ©s nommÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant :  [('Chrome', 'MISC'), ('Criteo', 'MISC'), ('LiveRamp', 'ORG'), ('Index Exchange', 'MISC')]\n",
      "AprÃ¨s :  [('machin', 'ORG'), ('Chrome', 'ORG'), ('Criteo', 'ORG'), ('LiveRamp', 'ORG'), ('Index Exchange', 'MISC')]\n"
     ]
    }
   ],
   "source": [
    "from spacy.pipeline import EntityRuler\n",
    "\n",
    "#nlp = spacy.load('fr_core_news_md')\n",
    "doc = nlp(\"Depuis que machin a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "print(\"Avant : \", [(ent.text, ent.label_) for ent in doc.ents])\n",
    "\n",
    "\n",
    "ruler = nlp.add_pipe(\"entity_ruler\", config={'overwrite_ents':True})\n",
    "patterns = [{\"label\": \"ORG\", \"pattern\": \"Chrome\"},\n",
    "            {\"label\":\"ORG\", \"pattern\":\"machin\"},\n",
    "    {\"label\":\"ORG\", \"pattern\":\"Criteo\"},\n",
    "    {\"label\":\"ORG\",\"pattern\":\"LiveRamp\"}]\n",
    "ruler.add_patterns(patterns)\n",
    "\n",
    "doc = nlp(\"Depuis que machin a annoncÃ© son intention de stopper d'ici deux ans les cookies tiers sur Chrome , son moteur de recherche qui est utilisÃ© par plus de 60 % de la population mondiale connectÃ©e, les Criteo, LiveRamp et autres Index Exchange se prÃ©parent Ã  ce qui peut Ãªtre considÃ©rÃ© comme un sÃ©isme, Ã  leur Ã©chelle.\")\n",
    "print(\"AprÃ¨s : \", [(ent.text, ent.label_) for ent in doc.ents])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
