{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rapid-replacement",
   "metadata": {},
   "source": [
    "# Correction exercice sur Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "partial-stevens",
   "metadata": {},
   "source": [
    "« À l'aide de la bibliothèque Spacy vous relèverez les personnages\n",
    "mentionnés dans Le ventre de Paris.\n",
    "Pour chacun des personnages qui apparaissent au moins trois fois, vous\n",
    "indiquerez les verbes dont ils sont sujet. »"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-referral",
   "metadata": {},
   "source": [
    "Il y a plusieurs façons de faire. Ici nous allons utiliser `Dependency Matcher` et tenter d'utiliser `displacy` pour visualiser les résultats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "enclosed-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import DependencyMatcher\n",
    "\n",
    "# Nous allons stocker les résultats dans l'objet Doc, dans un nouvel attribut\n",
    "# spacy a prévu un mécanisme d'extension pour ça\n",
    "from spacy.tokens import Doc\n",
    "Doc.set_extension(\"my_entities\", default=True)\n",
    "\n",
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "compound-yahoo",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = \"\"\n",
    "with open('files/Le_Ventre_de_Paris-chap1.txt') as input_f:\n",
    "    doc = nlp(input_f.read())\n",
    "doc._.my_entities = [] # on ajoute la liste my_entities comme une extension à l'objet Doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "combined-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dep(token, dep_type=\"flat:name\"):\n",
    "    \"\"\"\n",
    "    Cherche et retourne tous les tokens gouvernés\n",
    "    par 'token' avec la dépendance passée en paramètre\n",
    "    Par défaut 'flat:name' pour récupérer \"Madame François\"\n",
    "    plutôt que juste \"Madame\"\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    res.append(token)\n",
    "    for child in token.children:\n",
    "        if child.dep_ == dep_type:\n",
    "            res.append(child)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "frequent-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_persverb_event(matcher, doc, id, matches):\n",
    "    \"\"\"\n",
    "    Fonction callback de la méthode `matcher.add`\n",
    "    voir https://spacy.io/api/dependencymatcher#add\n",
    "    Ajoute une entité type 'PERSVERB' au couple sujet verbe détecté\n",
    "    \"\"\"\n",
    "    for m_id, t_ids in matches:\n",
    "        flats = get_dep(doc[t_ids[1]]) # le personnage et ses dépendants de type 'flat:name'\n",
    "        verb = doc[t_ids[0]]\n",
    "        # les entités sont stockées au format demandé pour une utilisation manuelle\n",
    "        # voir https://spacy.io/usage/visualizers#manual-usage\n",
    "        pers = {'start':flats[0].idx, 'end':flats[-1].idx+len(flats[-1])+1, 'label':\"PERS\"}\n",
    "        verb = {'start':verb.idx, 'end':verb.idx+len(verb)+1, 'label':'VERB'}\n",
    "        doc._.my_entities.extend([pers, verb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "nearby-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = DependencyMatcher(nlp.vocab)\n",
    "pattern = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",    \n",
    "        \"RIGHT_ATTRS\": {\"POS\": \"VERB\"}\n",
    "    },\n",
    "     {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"pers\",\n",
    "        \"RIGHT_ATTRS\": {\"DEP\": \"nsubj\", \"ENT_TYPE\": \"PER\"},  \n",
    "    }\n",
    "]\n",
    "matcher.add(\"pers-verb\", [pattern], on_match=add_persverb_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "vocal-positive",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "american-person",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "content = [\n",
    "    {'text': doc.text,\n",
    "    'ents': doc._.my_entities, # on retrouve les entités stockée en extension du Doc\n",
    "    'title': 'Personnages - verbes' \n",
    "    }\n",
    "]\n",
    "# export dans un fichier html\n",
    "# pour un roman entier le poids du fichier sera peut-être trop important\n",
    "html = displacy.render(content, style=\"ent\", manual=True, jupyter=False, minify=True)\n",
    "with open('./personnages-verbes.html', 'w') as output:\n",
    "    output.write(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addressed-junction",
   "metadata": {},
   "source": [
    "Ça ne répond pas exactement à la question puisqu'il fallait ne retenir que les personnages qui apparaissent au moins trois fois.  \n",
    "Pour ça on va travailler à partir de l'objet `matches`, résultat du `Dependancy Matcher`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "nutritional-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Madame François : regardait, pensa, causait\n",
      "- Florent : songeait, avançait, entra, mit, donné, aperçut, regardait, rappelait, aperçut, causait, intéressa, étonnait, regardait, allait, dit, regardait, levait, appuyer, écoutait, savait, tournait, demanda, crut, regardait, imagina, heurtait, raconta, promené, avait, entrât, entendit, reconnaissait, revit\n",
      "- Claude : regardait, arrêté, riait, dit, appela, entra, appelait, répéta, dit, ravi, dit, racontait, regardait, montra, monté, battait, murmurait\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "res = defaultdict(list)\n",
    "\n",
    "for m_id, t_ids in matches:\n",
    "        flats = get_dep(doc[t_ids[1]]) # le personnage et ses dépendants de type 'flat:name'\n",
    "        sujet = \" \".join([token.text for token in flats]) # on récupère la chaîne de caractères\n",
    "        verb = doc[t_ids[0]]\n",
    "        res[sujet].append(verb.text) # chaque verbe sera ajouté à la liste du personnage concerné\n",
    "\n",
    "for sujet in res:\n",
    "    if len(res[sujet]) > 2:\n",
    "        print(f\"- {sujet} : {', '.join(res[sujet])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-temperature",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
